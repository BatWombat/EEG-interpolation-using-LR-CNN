import numpy as np
import pandas as pd
from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import PolynomialFeatures
from sklearn.model_selection import KFold
from sklearn.metrics import mean_squared_error
import matplotlib.pyplot as plt

data = pd.read_csv("Plausible_N400.csv")

cols = ["FC1", "FC2", "CP1", "CP2"]
X = data[cols].values
y = data["Cz"].values
timestamps = data["Timestamp"].values

degree = 2

n_folds = 5

kf = KFold(n_splits=n_folds)

mse_scores = []
y_pred_all = np.empty_like(y)

for train_index, test_index in kf.split(X):

    X_train, X_test = X[train_index], X[test_index]
    y_train, y_test = y[train_index], y[test_index]

    poly = PolynomialFeatures(degree=degree)
    X_train_poly = poly.fit_transform(X_train)
    X_test_poly = poly.transform(X_test)

    model = LinearRegression()
    model.fit(X_train_poly, y_train)

    y_pred = model.predict(X_test_poly)

    mse = mean_squared_error(y_test, y_pred)
    mse_scores.append(mse)

    y_pred_all[test_index] = y_pred

avg_mse = np.mean(mse_scores)    
    
sort_idx = np.argsort(timestamps)
x_sorted = timestamps[sort_idx]
y_pred_sorted = y_pred_all[sort_idx]


unique_x, idx = np.unique(x_sorted, return_index=True)


mean_y = []
for i in range(len(unique_x)):
    if i < len(unique_x) - 1:
        mean_y.append(np.mean(y_pred_sorted[idx[i]:idx[i+1]]))
    else:
        mean_y.append(np.mean(y_pred_sorted[idx[i]:]))


plt.scatter(timestamps, y, label='True values', s=0.2)
plt.plot(unique_x, mean_y, label='Mean predicted values', color='r')
plt.legend()
plt.show()

print("MSE score of {}-fold-cross-validation polynomoial regression: {}".format(n_folds, avg_mse))
